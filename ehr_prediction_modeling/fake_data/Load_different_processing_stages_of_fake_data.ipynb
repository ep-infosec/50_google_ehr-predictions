{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQJlAoW5Bd_y"
      },
      "source": [
        "In this notebook, we load and display data at various processing stages: raw `FakeRecord`, sequential `FakePatient`, vectorized `GenericEventSequence`, and sparse encoded `tf.SequenceExample`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro2St71FgBsG"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "# Protocol buffers must first be compiled using `protoc`: see https://developers.google.com/protocol-buffers/docs/pythontutorial for details.",
        "from ehr_prediction_modeling.proto import fake_records_pb2\n",
        "from ehr_prediction_modeling.proto import fake_patient_pb2\n",
        "from ehr_prediction_modeling.proto import fake_generic_representation_pb2\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3-EGA03py8W"
      },
      "outputs": [],
      "source": [
        "data_dirpath = \"path/to/directory/that/stores/data\"  # @param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7zhehkHphMs"
      },
      "source": [
        "### Read Records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6vDPFwopg3i"
      },
      "outputs": [],
      "source": [
        "raw_data_path = os.path.join(data_dirpath, \"fake_raw_records.pb\")\n",
        "\n",
        "with open(raw_data_path, \"rb\") as f:\n",
        "  records = fake_records_pb2.FakeRecords.FromString(f.read()).records\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYzL_1uVDJK5"
      },
      "outputs": [],
      "source": [
        "print(f\"There are {len(records)} records in the fake dataset.\\nOne example is:\\n\\n{records[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b0Z2s9IEeCY"
      },
      "source": [
        "### Read Patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wUuDtEvEd_z"
      },
      "outputs": [],
      "source": [
        "patient_path = os.path.join(data_dirpath, \"fake_patients.pb\")\n",
        "\n",
        "with open(patient_path, \"rb\") as f:\n",
        "  patients = fake_patient_pb2.FakePatients.FromString(f.read()).patients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCS6Kx3BqnPG"
      },
      "outputs": [],
      "source": [
        "print(f\"There are {len(patients)} patients in the fake dataset.\\nOne example is:\\n\\n{patients[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz97KOGFXFvO"
      },
      "outputs": [],
      "source": [
        "all_admissions = []\n",
        "for patient in patients:\n",
        "  for episode in patient.episodes:\n",
        "    if episode.WhichOneof(\"episode_type\") == \"admission\":\n",
        "      all_admissions.append(episode.admission)\n",
        "\n",
        "print(f\"There are {len(all_admissions)} admissions in the fake dataset.\\nOne example is:\\n\\n{all_admissions[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlLArMJaXeS6"
      },
      "outputs": [],
      "source": [
        "all_clinical_events = []\n",
        "for patient in patients:\n",
        "  for episode in patient.episodes:\n",
        "    if episode.WhichOneof(\"episode_type\") == \"admission\":\n",
        "      for event in episode.admission.clinical_events:\n",
        "        all_clinical_events.append(event)\n",
        "\n",
        "print(f\"There are {len(all_clinical_events)} clinical events in admission in the fake dataset.\\nOne example is:\\n\\n{all_clinical_events[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmYh87nbpfmL"
      },
      "source": [
        "### Read GenericEventSequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY4n-StEpfjQ"
      },
      "outputs": [],
      "source": [
        "vectorized_path = os.path.join(data_dirpath, \"vectorized\", \"fake_vectorized_samples.pb\")\n",
        "\n",
        "with open(vectorized_path, \"rb\") as f:\n",
        "  event_sequences = fake_generic_representation_pb2.FakeGenericEventSequences.FromString(f.read()).generic_event_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmT9nIhNrFxg"
      },
      "outputs": [],
      "source": [
        "print(f\"There are {len(event_sequences)} event sequences in the fake dataset.\\nOne example is:\\n\\n{event_sequences[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-GnieUGEcuA"
      },
      "source": [
        "### `tf.SequenceExample`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAq584jvBdDD"
      },
      "outputs": [],
      "source": [
        "split = \"train\"  # @param\n",
        "seqex_path = os.path.join(data_dirpath, f\"standardize/{split}.tfrecords\")\n",
        "filenames = [seqex_path]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "iterator = raw_dataset.make_initializable_iterator()\n",
        "init = tf.initialize_all_variables()\n",
        "batch = iterator.get_next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJMBe1FNCA8C"
      },
      "outputs": [],
      "source": [
        "all_seqexs = []\n",
        "with tf.train.MonitoredTrainingSession() as sess:\n",
        "  sess.run(iterator.initializer)\n",
        "  sess.run(init)\n",
        "  while True:\n",
        "    all_seqexs.append(tf.train.SequenceExample.FromString(sess.run(batch)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll4UHg_IJ1CF"
      },
      "outputs": [],
      "source": [
        "print(f\"There are {len(all_seqexs)} sequence examples in the fake dataset for {split} split.\\nOne example is:\\n\\n{all_seqexs[0]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Load different processing stages of fake data.ipynb",
      "provenance": [
        {
          "file_id": "1IN7i9txgDRFs5Zt45yPLDoecqnPt-maZ",
          "timestamp": 1593452367408
        },
        {
          "file_id": "19tvFZCjRwoV9LwVxUp3gi3C2WQ8M86VT",
          "timestamp": 1593450070589
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
